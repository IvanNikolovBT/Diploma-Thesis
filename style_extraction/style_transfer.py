import sys
import os
import pandas as pd
import requests
import random
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, PROJECT_ROOT)
from poetry_DB import PoetryDB
import time
from tqdm import tqdm
import datetime
import boto3
import json
import re
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
import traceback
class StyleTransferLocal:
    
    def __init__(self,model="trajkovnikola/MKLLM-7B-Instruct"):

        self.system={"role": "system","content": 
            ("[INST]–†–∞–∑–≥–æ–≤–æ—Ä –ø–æ–º–µ—ì—É –∫–æ—Ä–∏—Å–Ω–∏–∫ –∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–∏–∫ –∑–∞ –µ–∫—Å—Ç—Ä–∞–∫—Ü–∏—ò–∞ –Ω–∞ —Å—Ç–∏–ª –º–∞–∫–µ–¥–æ–Ω—Å–∫–∞ –ø–æ–µ–∑–∏—ò–∞. –ê—Å–∏—Å—Ç–µ–Ω—Ç–æ—Ç –¥–∞–≤–∞ –∫–æ—Ä–∏—Å–Ω–∏, –¥–µ—Ç–∞–ª–Ω–∏ –∏ —ô—É–±–µ–∑–Ω–∏ –æ–¥–≥–æ–≤–æ—Ä–∏ –Ω–∞ –ø—Ä–∞—à–∞—ö–∞—Ç–∞ –Ω–∞ –∫–æ—Ä–∏—Å–Ω–∏–∫–æ—Ç.–ê–∫–æ –µ –ø—Ä–∏—Å—É—Ç–Ω–∞ –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ç–∞, –æ–¥–æ–≥–æ—Ä–∏ —Å–æ –î–ê –Ω–∞ –ø–æ—á–µ—Ç–æ–∫–æ—Ç, –ø—Ä–æ—Å–ª–µ–¥–µ–Ω–æ —Å–æ –æ–±—Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ. –ê–∫–æ –Ω–µ –µ –ø—Ä–∏—Å—É—Ç–Ω–∞, –æ–¥–≥–æ–≤–æ—Ä–∏ —Å–∞–º–æ —Å–æ –ù–ï –∏ –Ω–∏—à—Ç–æ –¥—Ä—É–≥–æ.[/INST]</s>.")}        
        self.db=PoetryDB()
        self.CSV_PATH="classification/cleaned_songs.csv"
        self.df=pd.read_csv(self.CSV_PATH)
        self.random_seed=47
        self.styles_path='style_extraction/vezilka_test.cvs'
        self.model=model
        self.styles=self.load_styles()
        self.client = boto3.client("bedrock-runtime",region_name="eu-central-1",)
    
    def load_styles(self):
        abs_path = os.path.abspath('style_extraction/styles.json')
        if not os.path.exists(abs_path):
            raise FileNotFoundError(f"‚ùå Styles file not found: {abs_path}")
        with open(abs_path, "r", encoding="utf-8") as f:
            return json.load(f)  
    def extract_n_random_songs_for_author(self, author_name='–ë–ª–∞–∂–µ –ö–æ–Ω–µ—Å–∫–∏', number_of_songs=10):
        author_songs = self.df[self.df['author'] == author_name]
        return author_songs.sample(
            n=min(number_of_songs, len(author_songs)),
            random_state=None  
        )
    def extract_n_random_styles_for_author(self, author_name='–ë–ª–∞–∂–µ –ö–æ–Ω–µ—Å–∫–∏', number_of_songs=10):
        styles=pd.read_csv('api_styles_all_in_one_text.csv')
        author_songs = styles[styles['author'] == author_name]
        return author_songs.sample(
            n=min(number_of_songs, len(author_songs)),
            random_state=None  
        )
    def extract_all_songs_for_author(self, author_name='–ë–ª–∞–∂–µ –ö–æ–Ω–µ—Å–∫–∏'):
        return self.df[self.df['author'] == author_name]
    
    def extract_style_from_song(self,song,target_feature,target_feature_definition):
        
        user_message_mk_llm = (
            f"{target_feature_definition}\n"
            "–û–≤–∞ —ò–∞ –ø—Ä–µ—Ç—Å—Ç–∞–≤—É–≤–∞ –¥–µ—Ñ–∏–Ω–∏—Ü–∏—ò–∞—Ç–∞, –Ω–µ —ò–∞ –¥–∞–≤–∞—ò –Ω–µ—ò–∑–µ, –≤–æ —Ç–≤–æ—ò–æ—Ç –æ–¥–≥–æ–≤–æ—Ä.\n\n"
            f"–ù–∞–ø–∏—à–∏ –∫—Ä–∞—Ç–æ–∫ –æ–ø–∏—Å –¥–∞–ª–∏ –∞–≤—Ç–æ—Ä–æ—Ç –Ω–∞ —Å–ª–µ–¥–Ω–∏–æ—Ç –ø–∞—Å—É—Å —ò–∞ —Å–æ–¥—Ä–∂–∏ –æ–≤–∞–∞ –æ—Å–æ–±–∏–Ω–∞: {target_feature}.\n"
            "–û–¥–≥–æ–≤–æ—Ä–∏ —Å–æ –î–∞ –∏–ª–∏ –ù–µ.\n\n"
            "–°–ª–µ–¥—É–≤–∞–∞—Ç –Ω–µ–∫–æ–ª–∫—É –ø—Ä–∏–º–µ—Ä–∏:\n\n"

            "–ü—Ä–∏–º–µ—Ä 1:\n"
            "–û—Å–æ–±–∏–Ω–∞: –°–∞—Ä–∫–∞–∑–∞–º\n"
            "–ü–∞—Å—É—Å: ‚Äû–û, –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ! –ë–∞—à —Å–∞–∫–∞–≤ –¥–∞ –º–∏ —Å–µ —Ä–∞—Å–∏–ø–µ —Ç–µ–ª–µ—Ñ–æ–Ω–æ—Ç —Å—Ä–µ–¥ –±–µ–ª –¥–µ–Ω.‚Äú\n"
            "–û–ø–∏—Å: –ê–≤—Ç–æ—Ä–æ—Ç –∑–±–æ—Ä—É–≤–∞ –∏—Ä–æ–Ω–∏—á–Ω–æ, –∏–∑—Ä–∞–∑—É–≤–∞—ò—ú–∏ —Å–ø—Ä–æ—Ç–∏–≤–Ω–æ –æ–¥ —Ç–æ–∞ —à—Ç–æ –º–∏—Å–ª–∏. –û–¥–≥–æ–≤–æ—Ä: –î–∞.\n\n"

            "–ü—Ä–∏–º–µ—Ä 2:\n"
            "–û—Å–æ–±–∏–Ω–∞: –°–∞—Ä–∫–∞–∑–∞–º\n"
            "–ü–∞—Å—É—Å: ‚Äû–ú–æ—ò–æ—Ç —Ç–µ–ª–µ—Ñ–æ–Ω —Å–µ —Ä–∞—Å–∏–ø–∞ –¥–µ–Ω–µ—Å –∏ —Ç–æ–∞ –º–∏ –≥–æ —É–Ω–∏—à—Ç–∏ –¥–µ–Ω–æ—Ç.‚Äú\n"
            "–û–ø–∏—Å: –ê–≤—Ç–æ—Ä–æ—Ç –¥–∏—Ä–µ–∫—Ç–Ω–æ –≥–æ –∏–∑—Ä–∞–∑—É–≤–∞ —Å–≤–æ–µ—Ç–æ –Ω–µ–∑–∞–¥–æ–≤–æ–ª—Å—Ç–≤–æ –±–µ–∑ –∏—Ä–æ–Ω–∏—ò–∞ –∏–ª–∏ –ø–æ—Ç—Å–º–µ–≤. –û–¥–≥–æ–≤–æ—Ä: –ù–µ.\n\n"

            
            "–ü—Ä–∏–º–µ—Ä 3:\n"
            "–û—Å–æ–±–∏–Ω–∞: –ê–∫—Ç–∏–≤–µ–Ω –≥–ª–∞—Å\n"
            "–ü–∞—Å—É—Å: ‚Äû–à–∞—Å —ò–∞ –Ω–∞–ø–∏—à–∞–≤ –ø–µ—Å–Ω–∞—Ç–∞ –∑–∞ –µ–¥–µ–Ω —á–∞—Å.‚Äú\n"
            "–û–ø–∏—Å: –ê–≤—Ç–æ—Ä–æ—Ç –∫–æ—Ä–∏—Å—Ç–∏ –∞–∫—Ç–∏–≤–µ–Ω –≥–ª–∞—Å –∫–∞–¥–µ —à—Ç–æ –ø–æ–¥–º–µ—Ç–æ—Ç —ò–∞ –∏–∑–≤—Ä—à—É–≤–∞ –¥–µ—ò—Å—Ç–≤–æ—Ç–æ. –û–¥–≥–æ–≤–æ—Ä: –î–∞.\n\n"

            f"–ü–∞—Å—É—Å:\n{song}\n\n–û–ø–∏—Å:"
        )
        user_message_vezilka = (
            f"{target_feature_definition}\n"
            "–û–≤–∞ —ò–∞ –ø—Ä–µ—Ç—Å—Ç–∞–≤—É–≤–∞ –¥–µ—Ñ–∏–Ω–∏—Ü–∏—ò–∞—Ç–∞, –Ω–µ —ò–∞ –¥–∞–≤–∞—ò –Ω–µ—ò–∑–µ, –≤–æ —Ç–≤–æ—ò–æ—Ç –æ–¥–≥–æ–≤–æ—Ä.\n\n"
            f"–û–¥–≥–æ–≤–æ—Ä–∏ –Ω–∞ –ø–∞—à–∞—ö–µ—Ç–æ –¥–∞–ª–∏ –∞–≤—Ç–æ—Ä–æ—Ç –Ω–∞ —Å–ª–µ–¥–Ω–∏–æ—Ç –ø–∞—Å—É—Å —ò–∞ —Å–æ–¥—Ä–∂–∏ –æ–≤–∞–∞ –æ—Å–æ–±–∏–Ω–∞: {target_feature}.\n"
            "–û–¥–≥–æ–≤–æ—Ä–∏ —Å–æ –î–∞,–ø—Ä–∏—Å—É—Ç–Ω–æ! –∏–ª–∏ –ù–µ!.\n\n"
            "–ë–∏–¥–∏ –º–Ω–æ–≥—É —Å—Ç—Ä–æ–≥ –ø—Ä–∏ —Å–≤–æ—ò–∞—Ç–∞ –æ–¥–ª—É–∫–∞, –∞–∫–æ —Å–∏ —Å–∏–≥—É—Ä–µ–Ω –¥–µ–∫–∞ –µ –ø—Ä–∏—Å—É—Ç–Ω–∞ –∫–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ç–∞, —Ç–æ–≥–∞—à –∑–∞–ø–∏—à–∏ –æ–¥–æ–≥–æ—Ä–∏ —Å–æ –¥–∞."
            f"–ü–∞—Å—É—Å:\n{song}\n\n–û–ø–∏—Å:"
        )
        messages = [self.system,{"role": "user", "content": user_message_vezilka}]

        payload_mk_llm = {
        "model": self.model,
        "messages": messages,
        "temperature": 0.3,
        "repetition_penalty":2,
        "frequency_penalty": 0.4,
        "presence_penalty": 0.3,
        "top_p": 0.9,
        "max_tokens":200,
        "stop": ["\n","\n\n","<|im_end|>"]}
        payload_vezilka = {
        "model": self.model,
        "messages": messages,
        "temperature": 0.4,
        "top_p": 0.9,
        "max_tokens":200,
        "stop": ["\n","\n\n","<|im_end|>"]}
        resp = requests.post("http://127.0.0.1:8080/v1/chat/completions",
        headers={"Content-Type": "application/json"},
        json=payload_vezilka)
        
        data = resp.json()
        return data["choices"][0]["message"]["content"].strip()
    
    def invoke_nova_micro(self, prompt, system):
        response = self.client.converse(
            modelId="arn:aws:bedrock:eu-central-1::inference-profile/eu.amazon.nova-micro-v1:0", 
            messages=[
                {
                    "role": "user",
                    "content": [{"text": prompt}]
                }
            ],
            system=[{"text": system}],
            inferenceConfig={
                "maxTokens": 1786,
                "temperature": 0.5,
                "topP": 0.9
            }
        )
        return response
    def invoke_other_model(self, prompt, system):
        response = self.client.converse(
            modelId="arn:aws:bedrock:eu-central-1::inference-profile/eu.amazon.nova-micro-v1:0", 
            messages=[
                {
                    "role": "user",
                    "content": [{"text": prompt}]
                }
            ],
            system=[{"text": system}],
            inferenceConfig={
                "maxTokens": 1786,
                "temperature": 0.5,
                "topP": 0.9
            }
        )
        return response
        
    def write_to_csv(self,author:str,song_title:str,result:json,output_path='api_styles_all_in_one_text.csv'):
        
        text=result['output']['message']['content'][0]['text'] 
        
                 
        
        input_tokens=result['usage']['inputTokens']
        output_tokens=result['usage']['outputTokens']
        total_tokens=result['usage']['totalTokens']
        
        ms=result['metrics']['latencyMs']
        
        row={'author':author,
             'song_title':song_title,
             'extracted_styles':text,
             'input_tokens':input_tokens,
             'output_tokens':output_tokens,
             'total_tokens':total_tokens,
             'ms':ms
             }
        api_csv = pd.DataFrame([row])
        file_exists = os.path.isfile(output_path)
        api_csv.to_csv(output_path, mode="a", index=False, header=not file_exists, encoding="utf-8")
        
    def extract_styles_from_song_using_api(self,song,author,song_title,output_path,without_def=True):
        system="–¢–∏ —Å–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–∏–∫ –∑–∞ –µ–∫—Å—Ç—Ä–∞–∫—Ü–∏—ò–∞ –Ω–∞ —Å—Ç–∏–ª –Ω–∞ –º–∞–∫–µ–¥–æ–Ω—Å–∫–∞ –ø–æ–µ–∑–∏—ò–∞."
        if without_def:
            prompt=self.create_full_prompt_without_definition(song)
        else:
            prompt=self.create_full_prompt_with_definition(song)
        result=self.invoke_nova_micro(prompt,system)
        self.write_to_csv(author,song_title,result,output_path)
    def extract_all_styles_api(self):
        output_path = 'api_styles_all_in_one_text.csv'

        if os.path.exists(output_path):
            result_df = pd.read_csv(output_path)
            print(f"Loaded existing CSV with {len(result_df)} rows.")
        else:
            cols = ['author', 'song_title', 'extracted_styles',
                    'input_tokens', 'output_tokens', 'total_tokens', 'ms']
            result_df = pd.DataFrame(columns=cols)
            result_df.to_csv(output_path, index=False)
            print("Created new CSV file.")

        i=0
        n=len(self.df)
        for _, song_row in self.df.iterrows():
            author = song_row['author']
            song_title = song_row['song_title']
            song=song_row['song_text']
            exists = (
                (result_df['author'] == author) &
                (result_df['song_title'] == song_title)
            ).any()

            if exists:
                print(f"Skipping {author} - {song_title} (already processed).")
                continue

            print(f"Processing {author} - {song_title}... {i}/{n} {i/n}")
            
            
            self.extract_styles_from_song_using_api(song=song,author=author,
                                                             song_title=song_title,output_path=output_path)


        print("‚úÖ All songs processed.")
        
    def extract_style_from_songs(self, sample_songs=[], output_dir=''):
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)

        output_path = os.path.join(output_dir, "extracted_styles.csv") if output_dir else "extracted_styles.csv"

        total_time=0
        file_exists = os.path.exists(output_path)

        for _, row in sample_songs.iterrows():
            author = row["author"]
            song = row["song_title"]
            original_song = row["song_text"]

            for category, definition in self.styles.items():
                start_time = time.time()

                extracted_text=self.extract_style_from_song(song,category,definition)
                
                end_time = time.time()
                time_needed = end_time - start_time

                
                df_row = pd.DataFrame([{
                    "author": author,
                    "song": song,
                    "style_feature_category": category,
                    "extracted_text": extracted_text,
                    #"original_song": original_song,
                    "time_needed": time_needed
                }])
                total_time+=time_needed
                
                df_row.to_csv(output_path, mode="a", index=False, header=not file_exists)
                file_exists = True

                
                print(f"[SAVED] Author='{author}', Song='{song}', Style='{category}', Time={time_needed:.2f}s")
            
            print(f'Total time {total_time:.2f}')
    def iterate_over_author(self,author):
        songs=self.extract_n_random_songs_for_author(author_name=author,number_of_songs=1)
        self.extract_style_from_songs(songs)

    def get_present_styles_for_song(self, title, author):
        self.df = pd.read_csv(self.styles_path)
        pattern = r'^–î–∞' 
        return self.df[
            (self.df['author']== author) & (self.df['song']==title) &
            (self.df['extracted_text'].str.match(pattern, na=False))
        ]
    def apply_styles_iterative(self, sf_styles, st_song_text, st_song_title, st_author,st_styles, log_path=None):
        if log_path is None:
            ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            log_path = f"song_style_log_{st_song_title or 'song'}_{ts}.txt"
            log_path = "".join(c for c in log_path if c.isalnum() or c in (' ','.','_','-')).rstrip()

        log_dir = os.path.dirname(log_path)
        if log_dir:
            os.makedirs(log_dir, exist_ok=True)

        new_song=st_song_text
        list1=sf_styles['style_feature_category'].unique().tolist()
        list2=st_styles['style_feature_category'].unique().tolist()
        diff = [item for item in list1 if item not in list2]
    
        cumulative=0
        with open(log_path, "a", encoding="utf-8") as log_file:
            i=0
            for style in diff:
                target_dif=self.styles[style]
                user_message = (
                        f"{target_dif}\n –û–≤–∞ —ò–∞ –ø—Ä–µ—Ç—Å—Ç–∞–≤—É–≤–∞ –¥–µ—Ñ–∏–Ω–∏—Ü–∏—ò–∞—Ç–∞, –Ω–µ —ò–∞ –¥–∞–≤–∞—ò –Ω–µ—ò–∑–µ, –≤–æ —Ç–≤–æ—ò–æ—Ç –æ–¥–≥–æ–≤–æ—Ä\n\n"
                        f"–ò—Å–∫–æ—Ä–∏—Å—Ç–∏ —ò–∞ –æ–≤–∞–∞ –æ—Å–æ–±–∏–Ω–∞ {style} –í–†–ó –ø–µ—Å–Ω–∞—Ç–∞: .\n"
                        f"–°–ª–µ–¥—É–≤–≤–∞—Ç –¥–≤–∞ –ø—Ä–∏–º–µ—Ä–∏:\n"
                        f"–ü–∞—Å—É—Å:\n{new_song}\n\n –û–±—Ä–∞–±–æ—Ç–µ–Ω–∞ –ø–µ—Å–Ω–∞: <–ì–µ–Ω–µ—Ä–∏—Ä–∞—ò —ò–∞ –ø–µ—Å–Ω–∞—Ç–∞ —Ç—É–∫–∞ –≤–µ –∑–∞–º–æ–ª—É–≤–∞–º>"
                    )
                new_system={"role": "system","content": 
                    ("[INST]–†–∞–∑–≥–æ–≤–æ—Ä –ø–æ–º–µ—ì—É –∫–æ—Ä–∏—Å–Ω–∏–∫ –∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–∏–∫  –∑–∞ –ø—Ä–∏–º–µ–Ω—É–≤–∞—ö–µ –Ω–∞  —Å—Ç–∏–ª –º–∞–∫–µ–¥–æ–Ω—Å–∫–∞ –ø–æ–µ–∑–∏—ò–∞. –ê—Å–∏—Å—Ç–µ–Ω—Ç–æ—Ç –¥–∞–≤–∞ –ø–µ—Å–Ω–∞ —Å–æ –ø—Ä–∏–º–µ–Ω–µ—Ç —Å—Ç–∏–ª –ø–æ –±–∞—Ä–∞—ö–µ –Ω–∞ –∫–æ—Ä–∏—Å–Ω–∏–∫–æ—Ç.[/INST]</s>.")}
                    
                messages = [new_system, {"role": "user", "content": user_message}]

                payload = {
                        "model": self.model,
                        "messages": messages,
                        "top_p": 0.9,
                        'early_stopping':True,
                        "frequency_penalty": 0.2,
                        "presence_penalty": 0.15,
                        'stop': ["<|im_end|>"],
                        "max_tokens":int(1.5*len(st_song_text)),
                    }
                start_time=time.time()
                resp = requests.post(
                            "http://127.0.0.1:8080/v1/chat/completions",
                            headers={"Content-Type": "application/json"},
                            json=payload,
                            timeout=200
                        )
                duration = time.time() - start_time
                cumulative += duration
                data = resp.json()
                new_song = data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
                print("\n" + "="*40)
                print(f"Iteration {i+1}/{len(diff)} - style added: {target_dif}")
                print(f"Duration: {duration:.3f} s")
                print("-" * 40)
                print(new_song)
                print("="*40 + "\n")
                i+=1
                log_file.write(f"--- Iteration {i+1} / {len(diff)} ---\n")
                log_file.write(f"Style added: {target_dif}\n")
                log_file.write(f"Author: {st_author}\n")
                log_file.write(f"Song title: {st_song_title}\n")
                log_file.write(f"Duration (s): {duration:.3f}\n")
                log_file.write(f"Cumulative duration (s): {cumulative:.3f}\n")
                log_file.write("Resulting song:\n")
                log_file.write(new_song + "\n\n")
                log_file.flush()
    def create_full_prompt_without_definition(self,song: str) -> str:

        features_text = "\n".join(
            [f"{feature}" for feature,definition in self.styles.items()]
        )
        
        prompt = (
            "–õ–∏—Å—Ç–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ —Å—Ç–∏–ª—Å–∫–∏ –∏ –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–∫–∏ –æ—Å–æ–±–∏–Ω–∏:\n\n"
            f"{features_text}\n\n"
            "–ü—Ä–æ—É—á–∏ –≥–æ —Å–ª–µ–¥–Ω–∏–æ—Ç –ø–∞—Å—É—Å –∏ –∑–∞ —Å–µ–∫–æ—ò–∞ –æ–¥ –æ–≤–∏–µ –æ—Å–æ–±–∏–Ω–∏ –æ–¥–≥–æ–≤–æ—Ä–∏ —Å–æ '–î–∞' –∏–ª–∏ '–ù–µ' –¥–∞–ª–∏ –∞–≤—Ç–æ—Ä–æ—Ç —ò–∞ –∫–æ—Ä–∏—Å—Ç–∏.\n\n"
            f"–ü–∞—Å—É—Å:\n{song}\n\n"
            "–û–¥–≥–æ–≤–æ—Ä (—Ñ–æ—Ä–º–∞—Ç–∏—Ä–∞—ò –ø–æ —Ä–µ–¥: '–§–∏–≥—É—Ä–∞—Ç–∏–≤–µ–Ω —ò–∞–∑–∏–∫: –î–∞', '–°–∞—Ä–∫–∞–∑–∞–º: –ù–µ', ...):"
        )
        
        return prompt   
    def create_full_prompt_with_definition(self,song: str) -> str:
       
        features_text = "\n".join(
            [f"{feature}" for feature,_ in self.styles.items()]
        )
        prompt = (
            "–õ–∏—Å—Ç–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ —Å—Ç–∏–ª—Å–∫–∏ –∏ –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–∫–∏ –æ—Å–æ–±–∏–Ω–∏:\n\n"
            f"{features_text}\n\n"
            "–ü—Ä–æ—É—á–∏ –≥–æ —Å–ª–µ–¥–Ω–∏–æ—Ç –ø–∞—Å—É—Å –∏ –∑–∞ —Å–µ–∫–æ—ò–∞ –æ–¥ –æ–≤–∏–µ –æ—Å–æ–±–∏–Ω–∏ –æ–¥–≥–æ–≤–æ—Ä–∏ —Å–æ '–î–∞' –∏–ª–∏ '–ù–µ' –¥–∞–ª–∏ –∞–≤—Ç–æ—Ä–æ—Ç —ò–∞ –∫–æ—Ä–∏—Å—Ç–∏.\n\n"
            f"–ü–∞—Å—É—Å:\n{song}\n\n"
            "–û–¥–≥–æ–≤–æ—Ä (—Ñ–æ—Ä–º–∞—Ç–∏—Ä–∞—ò –ø–æ —Ä–µ–¥: '–§–∏–≥—É—Ä–∞—Ç–∏–≤–µ–Ω —ò–∞–∑–∏–∫: –î–∞', '–°–∞—Ä–∫–∞–∑–∞–º: –ù–µ', ...):"
        )
        
        return prompt      
    def apply_styles_iterative_(self, sf_styles, st_song_text, st_song_title, st_author,st_styles, log_path=None):
    
        song = st_song_text

        
        if log_path is None:
            ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            log_path = f"song_style_log_{st_song_title or 'song'}_{ts}.txt"
            log_path = "".join(c for c in log_path if c.isalnum() or c in (' ','.','_','-')).rstrip()

        log_dir = os.path.dirname(log_path)
        if log_dir:
            os.makedirs(log_dir, exist_ok=True)

        cumulative = 0.0
        total_styles = len(sf_styles)
        target_features = []
        target_feature_definitions = []
        for _, row in sf_styles.iterrows():
            target_feature = row['style_feature_category']
            if target_feature not in st_styles['style_feature_category'].values:
                target_features.append(target_feature)
                target_feature_definitions.append(self.styles[target_feature])
            
        
        if not target_features:
            return song
        i=0
        with open(log_path, "a", encoding="utf-8") as log_file:
            for target_feature,target_definition in zip(target_features,target_feature_definitions):
                
                
                example_1="–û—Å–æ–±–∏–Ω–∞:–°–∞—Ä–∫–∞–∑–∞–º\n–û—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ: –î–µ–Ω–µ—Å —Ä–∞–±–æ—Ç–µ–≤ —Ü–µ–ª –¥–µ–Ω –±–µ–∑ –ø–∞—É–∑–∞.\n–°–æ ‚Äû–°–∞—Ä–∫–∞–∑–∞–º‚Äú: –û, –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ, —Ç–æ–∫–º—É —Ç–æ–∞ –º–∏ —Ç—Ä–µ–±–∞—à–µ ‚Äî —É—à—Ç–µ –µ–¥–µ–Ω –¥–µ–Ω –±–µ–∑ –æ–¥–º–æ—Ä!\n"
                example_2="–û—Å–æ–±–∏–Ω–∞:–ê–∫—Ç–∏–≤–µ–Ω –≥–ª–∞—Å\n–û—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ: –ü–∏—Å–º–æ—Ç–æ –±–µ—à–µ –∏—Å–ø—Ä–∞—Ç–µ–Ω–æ –æ–¥ –º–µ–Ω–µ.\n–°–æ ‚Äû–ê–∫—Ç–∏–≤–µ–Ω –≥–ª–∞—Å‚Äú: –à–∞—Å –≥–æ –∏—Å–ø—Ä–∞—Ç–∏–≤ –ø–∏—Å–º–æ—Ç–æ\n"
                
                user_message = (
                    f"{target_definition}\n –û–≤–∞ —ò–∞ –ø—Ä–µ—Ç—Å—Ç–∞–≤—É–≤–∞ –¥–µ—Ñ–∏–Ω–∏—Ü–∏—ò–∞—Ç–∞, –Ω–µ —ò–∞ –¥–∞–≤–∞—ò –Ω–µ—ò–∑–µ, –≤–æ —Ç–≤–æ—ò–æ—Ç –æ–¥–≥–æ–≤–æ—Ä\n\n"
                    f"–ò—Å–∫–æ—Ä–∏—Å—Ç–∏ —ò–∞ –æ–≤–∞–∞ –æ—Å–æ–±–∏–Ω–∞ {target_feature} –í–†–ó –ø–µ—Å–Ω–∞—Ç–∞: .\n"
                    f"–ö–∞–∫–æ –æ–¥–≥–æ–≤–æ—Ä –≤—Ä–∞—Ç–∏ —ò–∞ –Ω–∞–∑–∞–¥ –ø–µ—Å–Ω–∞—Ç–∞, –Ω–æ —Å–æ –ø—Ä–∏–º–µ–Ω–µ—Ç {target_feature} –≤—Ä–∑ –Ω–µ—ò–∑–µ. –û–≤–∞–∞ –µ –∫–ª—É—á–Ω–æ.\n"
                    f"–°–ª–µ–¥—É–≤–≤–∞—Ç –¥–≤–∞ –ø—Ä–∏–º–µ—Ä–∏:\n"
                    f'{example_1}'
                    f'{example_2}'
                    f"–ü–∞—Å—É—Å:\n{song}\n\n –û–±—Ä–∞–±–æ—Ç–µ–Ω–∞ –ø–µ—Å–Ω–∞:"
                )
                
               
                new_system={"role": "system","content": 
                ("[INST]–†–∞–∑–≥–æ–≤–æ—Ä –ø–æ–º–µ—ì—É –∫–æ—Ä–∏—Å–Ω–∏–∫ –∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–∏–∫  –∑–∞ –ø—Ä–∏–º–µ–Ω—É–≤–∞—ö–µ –Ω–∞  —Å—Ç–∏–ª –º–∞–∫–µ–¥–æ–Ω—Å–∫–∞ –ø–æ–µ–∑–∏—ò–∞. –ê—Å–∏—Å—Ç–µ–Ω—Ç–æ—Ç –¥–∞–≤–∞ –∫–æ—Ä–∏—Å–Ω–∏, –¥–µ—Ç–∞–ª–Ω–∏ –∏ —ô—É–±–µ–∑–Ω–∏ –æ–¥–≥–æ–≤–æ—Ä–∏ –Ω–∞ –ø—Ä–∞—à–∞—ö–∞—Ç–∞ –Ω–∞ –∫–æ—Ä–∏—Å–Ω–∏–∫–æ—Ç.[/INST]</s>.")}
                #probaj so indivdualni primeri pomali 
                #predefinirani stilovi na ekstrakjcija i da proveri dali e prisuten
                # (/) vsushnost razlika na stilovi
                #ostavi default
                #podobro odednash site i da se zpaishi akko zakluchok
                messages = [new_system, {"role": "user", "content": user_message}]

                payload = {
                    "model": self.model,
                    "messages": messages,
                    "top_p": 0.9,
                    'early_stopping':True,
                    "frequency_penalty": 0.2,
                    "presence_penalty": 0.15,
                    'stop': ["<|im_end|>"],
                    "max_tokens":int(1.5*len(song)),
                }
                """"output_ids = self.model.generate(input_ids=data_x_input_ids,
                                                 attention_mask=data_x_attention_mask,
                                                 max_new_tokens=max_length,
                                                 eos_token_id=tokenizer.eos_token_id,
                                                 pad_token_id=tokenizer.pad_token_id,
                                                 early_stopping=True,
                                                 num_return_sequences=1,
                                                 # no_repeat_ngram_size=2,
                                                 # repetition_penalty=2.0,
                                                 do_sample=False,
                                                 # top_p=0.5
                                                 )"""
                
                start_time = time.time()
                try:
                    resp = requests.post(
                        "http://127.0.0.1:8080/v1/chat/completions",
                        headers={"Content-Type": "application/json"},
                        json=payload,
                        timeout=200
                    )
                    duration = time.time() - start_time

                    if resp.ok:
                        data = resp.json()
                        new_song = data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()

                        if not new_song:
                            new_song = song
                            note = f" (empty response ‚Äî kept previous song text)"
                        else:
                            note = ""
                    else:
                        new_song = song
                        note = f" (request failed: status {resp.status_code})"

                except Exception as e:
                    duration = time.time() - start_time
                    new_song = song
                    note = f" (exception during request: {e})"

                cumulative += duration
                song = new_song

                
                print("\n" + "="*40)
                print(f"Iteration {i+1}/{total_styles} - style added: {target_feature}")
                print(f"Duration: {duration:.3f} s{note}")
                print("-" * 40)
                print(song)
                print("="*40 + "\n")
                i+=1
                log_file.write(f"--- Iteration {i+1} / {total_styles} ---\n")
                log_file.write(f"Style added: {target_feature}\n")
                log_file.write(f"Author: {st_author}\n")
                log_file.write(f"Song title: {st_song_title}\n")
                log_file.write(f"Duration (s): {duration:.3f}\n")
                log_file.write(f"Cumulative duration (s): {cumulative:.3f}\n")
                if note:
                    log_file.write(f"Note: {note}\n")
                log_file.write("Resulting song:\n")
                log_file.write(song + "\n\n")
                log_file.flush()

        return song, log_path
    def apply_styles_all_at_once(self, sf_styles, st_song_text,st_styles):
        song = st_song_text
        max_words = len(st_song_text.split()) 
        target_features = []
        target_feature_definitions = []
        
        
        for _, row in sf_styles.iterrows():
            target_feature = row['style_feature_category']
            if target_feature not in st_styles['style_feature_category'].values:
                target_features.append(target_feature)
                target_feature_definitions.append(self.styles[target_feature])
        
        
        if not target_features:
            return song
        print(target_features)
        definitions_text = "–î–µ—Ñ–∏–Ω–∏—Ü–∏–∏ –Ω–∞ –æ—Å–æ–±–∏–Ω–∏:\n" + "\n".join(
            [f"{i+1}. {target_features[i]} ‚Äì {target_feature_definitions[i]}" for i in range(len(target_features))]
        )
        
        example_1 = (
            "–û—Å–æ–±–∏–Ω–∞: –°–∞—Ä–∫–∞–∑–∞–º\n"
            "–û—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ: –î–µ–Ω–µ—Å —Ä–∞–±–æ—Ç–µ–≤ —Ü–µ–ª –¥–µ–Ω –±–µ–∑ –ø–∞—É–∑–∞.\n"
            "–°–æ ‚Äû–°–∞—Ä–∫–∞–∑–∞–º‚Äú: –û, –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ, —Ç–æ–∫–º—É —Ç–æ–∞ –º–∏ —Ç—Ä–µ–±–∞—à–µ ‚Äî —É—à—Ç–µ –µ–¥–µ–Ω –¥–µ–Ω –±–µ–∑ –æ–¥–º–æ—Ä!\n"
        )
        example_2 = (
            "–û—Å–æ–±–∏–Ω–∞: –ê–∫—Ç–∏–≤–µ–Ω –≥–ª–∞—Å\n"
            "–û—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ: –ü–∏—Å–º–æ—Ç–æ –±–µ—à–µ –∏—Å–ø—Ä–∞—Ç–µ–Ω–æ –æ–¥ –º–µ–Ω–µ.\n"
            "–°–æ ‚Äû–ê–∫—Ç–∏–≤–µ–Ω –≥–ª–∞—Å‚Äú: –à–∞—Å –≥–æ –∏—Å–ø—Ä–∞—Ç–∏–≤ –ø–∏—Å–º–æ—Ç–æ.\n"
        )
        
       
        styles_list = ", ".join(target_features)
        user_message = (
            f"{definitions_text}\n"
            f"–û–≤–∏–µ —Å–µ  –¥–µ—Ñ–∏–Ω–∏—Ü–∏–∏—Ç–µ –Ω–∞ —Å—Ç–∏–ª–æ–≤–∏—Ç–µ, –Ω–µ –≥–∏ –¥–∞–≤–∞—ò –Ω–∏–≤ –≤–æ —Ç–≤–æ—ò–æ—Ç –æ–¥–≥–æ–≤–æ—Ä.\n\n"
            f"–ò—Å–∫–æ—Ä–∏—Å—Ç–∏ –≥–∏ —Å–∏—Ç–µ –æ–≤–∏–µ –æ—Å–æ–±–∏–Ω–∏: {styles_list} –í–†–ó –ø–µ—Å–Ω–∞—Ç–∞ –∏—Å—Ç–æ–≤—Ä–µ–º–µ–Ω–æ.\n"
            f"–ö–∞–∫–æ –æ–¥–≥–æ–≤–æ—Ä –≤—Ä–∞—Ç–∏ —ò–∞ –Ω–∞–∑–∞–¥ –ø–µ—Å–Ω–∞—Ç–∞, –Ω–æ —Å–æ –ø—Ä–∏–º–µ–Ω–µ—Ç–∏ {styles_list} –≤—Ä–∑ –Ω–µ—ò–∑–µ. –û–≤–∞–∞ –µ –∫–ª—É—á–Ω–æ.\n"
            f"–°–ª–µ–¥—É–≤–∞–∞—Ç –¥–≤–∞ –ø—Ä–∏–º–µ—Ä–∏:\n"
            f'{example_1}\n'
            f'{example_2}\n'
            f"–ü–∞—Å—É—Å:\n{song}\n\n–û–±—Ä–∞–±–æ—Ç–µ–Ω–∞ –ø–µ—Å–Ω–∞ —Å–æ –ø—Ä–∏–º–µ–Ω–µ—Ç–∏ —Å—Ç–∏–ª–æ–≤–∏:"
        )
        
        new_system = {
            "role": "system",
            "content": "[INST]–†–∞–∑–≥–æ–≤–æ—Ä –ø–æ–º–µ—ì—É –∫–æ—Ä–∏—Å–Ω–∏–∫ –∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–∏–∫ –∑–∞ –ø—Ä–∏–º–µ–Ω—É–≤–∞—ö–µ –Ω–∞ —Å—Ç–∏–ª –º–∞–∫–µ–¥–æ–Ω—Å–∫–∞ –ø–æ–µ–∑–∏—ò–∞. –ê—Å–∏—Å—Ç–µ–Ω—Ç–æ—Ç –¥–∞–≤–∞ –∫–æ—Ä–∏—Å–Ω–∏, –¥–µ—Ç–∞–ª–Ω–∏ –∏ —ô—É–±–µ–∑–Ω–∏ –æ–¥–≥–æ–≤–æ—Ä–∏ –Ω–∞ –ø—Ä–∞—à–∞—ö–∞—Ç–∞ –Ω–∞ –∫–æ—Ä–∏—Å–Ω–∏–∫–æ—Ç.[/INST]</s>"
        }
        messages = [new_system, {"role": "user", "content": user_message}]
        
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": 0.5,
            "top_p": 0.9,
            "stop": ["\n\n\n","<|im_end|>"],
            "max_tokens":int(1.5*max_words),
  
        }
        
        start = time.time()
        resp = requests.post(
            "http://127.0.0.1:8080/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json=payload
        )
        print(f'Time needed for applying all styles: {time.time() - start}')
        
        data = resp.json()
        return data["choices"][0]["message"]["content"].strip()
    def transfer_style(self,sf_author,sf_song_title,st_author,st_song_text,st_song_title): 
        #self,sf_author,sf_song_title):
        sf_selected=self.get_present_styles_for_song(sf_song_title,sf_author)
        st_selected=self.get_present_styles_for_song(st_song_title,st_author)
        return self.apply_styles_iterative(sf_styles=sf_selected,st_song_text=st_song_text,st_styles=st_selected,st_song_title=st_song_title,st_author=st_author)
    def extract_style_from_all_songs(self, songs_csv, output_filename="extracted_styles_1.csv", save_every=100):    
        if not os.path.exists(songs_csv):
            raise FileNotFoundError(f"CSV file not found: {songs_csv}")
        sample_songs = pd.read_csv(songs_csv)
        print(f"üìÑ Loaded {len(sample_songs)} songs from {songs_csv}")

        
        script_dir = os.path.dirname(os.path.abspath(__file__))
        output_path = os.path.join(script_dir, output_filename)
        
        if os.path.exists(output_path):
            existing_df = pd.read_csv(output_path)
            processed = set(zip(
                existing_df["author"],
                existing_df["song"],
                existing_df["style_feature_category"]
            ))
            print(f"üîÅ Found existing file with {len(processed)} processed entries. Resuming...")
            file_exists = True
        else:
            processed = set()
            file_exists = False
            print("üÜï No existing file found. Starting fresh.")

        buffer = []
        total_time = 0.0
        counter = 0

        total_items = len(sample_songs) * len(self.styles)
        pbar = tqdm(total=total_items, desc="Extracting styles", ncols=100)

        for _, row in sample_songs.iterrows():
            author = row["author"]
            song = row["song_title"]
            

            for category, definition in self.styles.items():
                key = (author, song, category)
                if key in processed:
                    pbar.update(1)
                    continue

                start_time = time.time()
                try:
                    extracted_text = self.extract_style_from_song(song, category, definition)
                except Exception as e:
                    print(f"‚ùå Error processing {key}: {e}")
                    pbar.update(1)
                    continue

                time_needed = time.time() - start_time
                total_time += time_needed

                buffer.append({
                    "author": author,
                    "song": song,
                    "style_feature_category": category,
                    "extracted_text": extracted_text,
                    "time_needed": time_needed
                })
                processed.add(key)
                counter += 1
                pbar.update(1)

                
                if counter % save_every == 0:
                    pd.DataFrame(buffer).to_csv(output_path, mode="a", index=False, header=not file_exists)
                    file_exists = True
                    buffer = []
                    print(f"üíæ Progress saved ({counter} items processed so far).")

        
        if buffer:
            pd.DataFrame(buffer).to_csv(output_path, mode="a", index=False, header=not file_exists)
            print("üíæ Final save completed.")

        pbar.close()
        print(f"\nüèÅ Extraction complete. Total time: {total_time:.2f}s")  
    def create_csv_for_extraction(self,
                                number_of_songs=10,
                                styles_path='api_styles_all_in_one_text.csv',
                                results_path='author_songs_to_create_only_with_styles.csv'):
        
        extracted_styles = pd.read_csv(styles_path)
        unique_authors = extracted_styles['author'].unique()

        columns = [
            'author',
            'name_of_sample_song',
            'styles',
            'name_of_new_song',
            'song',
            'input',
            'output',
            'total',
            'ms'
        ]

        if not os.path.exists(results_path):
            result_df = pd.DataFrame(columns=columns)
            result_df.to_csv(results_path, index=False)

        existing_df = pd.read_csv(results_path)

        new_rows = []
        for author in unique_authors:
            songs_for_author = self.extract_n_random_styles_for_author(author, number_of_songs)
            
            for _, song_info in songs_for_author.iterrows():
                row = {
                    'author': song_info['author'],
                    'name_of_sample_song': song_info['song_title'],
                    'styles': song_info['extracted_styles'],
                    'name_of_new_song': '',
                    'song': '',
                    'input': '',
                    'output': '',
                    'total': '',
                    'ms': ''
                }
                new_rows.append(row)

        updated_df = pd.concat([existing_df, pd.DataFrame(new_rows)], ignore_index=True)

        updated_df.to_csv(results_path, index=False)
        print(f"‚úÖ CSV updated/created at: {results_path}")  
    
    def create_only_styles_prompt(self,*key_lists):
  
        all_keys = set()
        for keys in key_lists:
            all_keys.update(keys)

        sorted_keys = sorted(all_keys)
        styles_string="".join(f"- {key}" for key in sorted_keys)
        prompt = "–°—Ç–∏–ª—Å–∫–∏ —Ñ–∏–≥—É—Ä–∏ —à—Ç–æ —Ç—Ä–µ–±–∞ –¥–∞ —Å–µ –∏—Å–∫–æ—Ä–∏—Å—Ç–∞—Ç:\n"
        prompt += "\n".join(f"- {key}" for key in sorted_keys)
        prompt+="\n–ò–∑–≥–µ–Ω–µ—Ä–∏—Ä–∞—ò –º–∞–∫–µ–¥–æ–Ω—Å–∫–∞ –ø–æ–µ–∑–∏—ò–∞ –∫–æ—Ä–∏—Å—Ç–µ—ò—ú–∏ –≥–∏ –≥–æ—Ä–µ –Ω–∞–≤–µ–¥–µ–Ω–∏—Ç–µ –Ω–∞—Å–æ–∫–∏ –Ω–∞ –∑–Ω–∞—á–µ—ö–µ.  –ü–µ—Å–Ω–∞—Ç–∞ –º–æ—Ä–∞ –¥–∞ –∏–º–∞ –Ω–∞—Å–ª–æ–≤. –ù–∞—Å–ª–æ–≤–æ—Ç –∑–∞–ø–∏—à–∏ –≥–æ –≤–æ —Å–ª–µ–¥–Ω–∏–æ—Ç —Ñ–æ—Ä–º–∞—Ç "
        prompt+="<–ù–ê–°–õ–û–í>–¢—É–∫–∞ –≤–º–µ—Ç–Ω–∏ –≥–æ –Ω–∞—Å–ª–æ–≤–æ—Ç </–ù–ê–°–õ–û–í> . –ü–µ—Å–Ω–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞—ò —ò–∞ –≤–æ —Ä–∞–º–º–∫–∏—Ç–µ –Ω–∞ <–ü–ï–°–ù–ê>–¢—É–∫–∞ –≤–º–µ—Ç–Ω–∏ —ò–∞ –ø–µ—Å–Ω–∞—Ç–∞ </–ü–ï–°–ù–ê>."
        prompt+="–ù–µ –≥–∏ –∫–æ—Ä–∏—Å—Ç–∏ –∏–º–∏—ö–∞—Ç–∞ –Ω–∞ —Å–∞–º–∏—Ç–µ –Ω–∞—Å–æ–∫–∏ –Ω–∞ –∑–Ω–∞—á–µ—ö–µ.–ë–∏–¥–∏ –∫—Ä–µ–∞—Ç–∏–≤–µ–Ω! –î–∞ –Ω–µ–º–∞ –ø—Ä–µ–º–Ω–æ–≥—É —Ä–∏–º–∞, –∑–∞—Ç–æ–∞ —à—Ç–æ —Ç–æ–∞ –Ω–∞–ª–∏–∫—É–≤–∞ –Ω–∞ –ø–µ—Å–Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–∞ –æ–¥ –º–æ–¥–µ–ª. –ö–æ—Ä–∏—Å—Ç–∏ –Ω–µ—Ä–µ–≥—É–ª–∞—Ä–Ω–∏ –∑–±–æ—Ä–æ–≤–∏."
        return prompt,styles_string
    
    def create_idf_styles_prompt(self, author, all_author_words, num_words=10, styles=None):
        if styles is None:
            styles = []

        
        styles = [s.strip() for s in styles if isinstance(s, str) and s.strip()]

        
        most_common_words = all_author_words['expressive_words'][author]
        top_words = [word for word, _ in most_common_words[:num_words]]

       
        styles_string = "\n".join(f"- {key}" for key in styles)
        words_string = ", ".join(top_words)

        
        prompt = "–°—Ç–∏–ª—Å–∫–∏ —Ñ–∏–≥—É—Ä–∏ —à—Ç–æ —Ç—Ä–µ–±–∞ –¥–∞ —Å–µ –∏—Å–∫–æ—Ä–∏—Å—Ç–∞—Ç:\n"
        prompt += styles_string if styles_string else "- (–Ω–µ–º–∞ –∏–∑–±—Ä–∞–Ω–∏ —Å—Ç–∏–ª–æ–≤–∏)"
        prompt += "\n\n–ù–∞—ò—á–µ—Å—Ç–∏ –∑–±–æ—Ä–æ–≤–∏ –∫–æ–∏ —Ç—Ä–µ–±–∞ –¥–∞ —Å–µ –∏—Å–∫–æ—Ä–∏—Å—Ç–∞—Ç –≤–æ –ø–µ—Å–Ω–∞—Ç–∞:\n"
        prompt += words_string
        prompt += (
            "\n\n–ò–∑–≥–µ–Ω–µ—Ä–∏—Ä–∞—ò –º–∞–∫–µ–¥–æ–Ω—Å–∫–∞ –ø–æ–µ–∑–∏—ò–∞ –∫–æ—Ä–∏—Å—Ç–µ—ò—ú–∏ –≥–∏ –≥–æ—Ä–µ–Ω–∞–≤–µ–¥–µ–Ω–∏—Ç–µ —Å—Ç–∏–ª—Å–∫–∏ —Ñ–∏–≥—É—Ä–∏ –∏ –∑–±–æ—Ä–æ–≤–∏. "
            "–ü–µ—Å–Ω–∞—Ç–∞ –º–æ—Ä–∞ –¥–∞ –∏–º–∞ –Ω–∞—Å–ª–æ–≤. –ù–∞—Å–ª–æ–≤–æ—Ç –∑–∞–ø–∏—à–∏ –≥–æ –≤–æ —Å–ª–µ–¥–Ω–∏–æ—Ç —Ñ–æ—Ä–º–∞—Ç: "
            "<–ù–ê–°–õ–û–í>–¢—É–∫–∞ –≤–º–µ—Ç–Ω–∏ –≥–æ –Ω–∞—Å–ª–æ–≤–æ—Ç</–ù–ê–°–õ–û–í>. "
            "–ü–µ—Å–Ω–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞—ò —ò–∞ –≤–æ —Ä–∞–º–∫–∏—Ç–µ –Ω–∞ <–ü–ï–°–ù–ê>–¢—É–∫–∞ –≤–º–µ—Ç–Ω–∏ —ò–∞ –ø–µ—Å–Ω–∞—Ç–∞</–ü–ï–°–ù–ê>. "
            "–ù–µ –≥–∏ –∫–æ—Ä–∏—Å—Ç–∏ –∏–º–∏—ö–∞—Ç–∞ –Ω–∞ —Å–∞–º–∏—Ç–µ –Ω–∞—Å–æ–∫–∏ –Ω–∞ –∑–Ω–∞—á–µ—ö–µ. –ë–∏–¥–∏ –∫—Ä–µ–∞—Ç–∏–≤–µ–Ω!"
        )

        return prompt, "\n".join(styles)

    def fill_csv_using_only_styles(self):
        system = '–¢–∏ —Å–∏ –ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–∏–∫ –Ω–∞–º–µ–Ω–µ—Ç –∑–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞—ö–µ –Ω–∞ –º–∞–∫–µ–¥–æ–Ω—Å–∫–∞ –ø–æ–µ–∑–∏—ò–∞.'
        songs_to_apply = pd.read_csv('author_songs_to_create_only_with_styles.csv')
        
        start_time = time.time()
        total_time=0
        total_songs = len(songs_to_apply)
        
        for idx, row in songs_to_apply.iterrows():
            try:
                extracted_styles = self.extract_style_pairs(row['styles'], only_present=True)
                styles_to_apply = extracted_styles.keys()
                prompt,styles_string = self.create_only_styles_prompt(styles_to_apply)
                
                result = self.invoke_nova_micro(prompt=prompt, system=system)
                
               
                if not result or 'output' not in result or 'message' not in result['output']:
                    print(f"[{idx+1}/{total_songs}] Warning: No valid reply from API for song '{row['name_of_sample_song']}' by '{row['author']}'")
                    continue
                
                self.write_to_csv_only_styles(
                    row['author'],
                    row['name_of_sample_song'],
                    styles_string,
                    result
                )
                
                elapsed = time.time() - start_time
                total_time+=elapsed
                print(f"[{idx+1}/{total_songs}] Processed '{row['name_of_sample_song']}' by '{row['author']}' - Time elapsed: {elapsed:.2f}s-Total {total_time:.2f}")
            
            except Exception as e:
                print(f"[{idx+1}/{total_songs}] Error processing '{row['name_of_sample_song']}' by '{row['author']}': {e}")
   
    def fill_csv_using__styles_idf(self,styles_from='author_songs_to_create_only_with_styles.csv', model='claude', output_path='author_songs_created_using_styles_idf_stop_words_removed.csv'):
        system = '–¢–∏ —Å–∏ –ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–∏–∫ –Ω–∞–º–µ–Ω–µ—Ç –∑–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞—ö–µ –Ω–∞ –º–∞–∫–µ–¥–æ–Ω—Å–∫–∞ –ø–æ–µ–∑–∏—ò–∞.'
        songs_to_apply = pd.read_csv(styles_from)
        
        start_time = time.time()
        total_time = 0
        total_songs = len(songs_to_apply)
        all_author_words = self.analyze_author_text()

        for idx, row in songs_to_apply.iterrows():
            song_title = row['name_of_sample_song']
            author = row['author']
            print(f"[{idx+1}/{total_songs}] Processing '{song_title}' by '{author}'")

            extracted_styles = self.extract_style_pairs(row['styles'], only_present=True)
            styles_to_apply = list(extracted_styles.keys())
            prompt, styles_string = self.create_idf_styles_prompt(
                author=author,
                all_author_words=all_author_words,
                styles=styles_to_apply
            )

            success = False
            retries = 0
            max_retries = 3

            while not success and retries < max_retries:
                try:
                    start = time.time()

                    if model == 'nova':
                        result = self.invoke_nova_micro(prompt, system)
                    elif model == 'claude':
                        result = self.invoke_claude_model(prompt, system)

                    if not result or 'output' not in result or 'message' not in result['output']:
                        raise ValueError("Invalid API response")

                    #
                    self.write_to_csv_only_styles(
                        author, song_title, styles_string, result,
                        output_path=output_path
                    )

                    elapsed = time.time() - start
                    total_time += elapsed
                    print(f"[{idx+1}/{total_songs}] ‚úÖ Processed '{song_title}' - {elapsed:.2f}s (Total {total_time:.2f}s)")

                    
                    wait_time = random.uniform(5, 10)
                    print(f"Waiting {wait_time:.2f}s before next song...")
                    time.sleep(wait_time)

                    success = True

                except Exception as e:
                    retries += 1
                    print(f"[{idx+1}/{total_songs}] ‚ö†Ô∏è Error processing '{song_title}': {e}")
                    traceback.print_exc()

                    if "ThrottlingException" in str(e):
                        wait_time = random.uniform(20, 40)
                        print(f"Throttled! Waiting {wait_time:.2f}s before retrying...")
                    else:
                        wait_time = random.uniform(10, 20)
                        print(f"Retrying after {wait_time:.2f}s...")
                    
                    time.sleep(wait_time)   

            if not success:
                print(f"[{idx+1}/{total_songs}] ‚ùå Skipping '{song_title}' after {max_retries} failed attempts.")
    def write_to_csv_only_styles(self, author, song_title, styles_to_apply, result, output_path='author_songs_created_only_with_styles.csv'):
        text = result['output']['message']['content'][0]['text']

        input_tokens = result['usage']['inputTokens']
        output_tokens = result['usage']['outputTokens']
        total_tokens = result['usage']['totalTokens']

        ms = result['metrics']['latencyMs']

        
        title_match = re.search(r'<–ù–ê–°–õ–û–í>\s*(.*?)\s*</–ù–ê–°–õ–û–í>', text, re.DOTALL)
        name_of_new_song = title_match.group(1).strip() if title_match else 'no_title_found'

        
        song_match = re.search(r'<–ü–ï–°–ù–ê>\s*(.*?)\s*</–ü–ï–°–ù–ê>', text, re.DOTALL)
        
        song_content = song_match.group(1).strip() if song_match else 'no_song_found'
        text = f"{name_of_new_song}\n\n{song_content.strip()}"

        row = {
            'author': author,
            'song_title': song_title,
            'styles_to_apply': styles_to_apply,
            'name_of_new_song': name_of_new_song,
            'new_song': text,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'total_tokens': total_tokens,
            'ms': ms
        }

        api_csv = pd.DataFrame([row])
        file_exists = os.path.isfile(output_path)
        api_csv.to_csv(output_path, mode="a", index=False, header=not file_exists, encoding="utf-8")
    def extract_style_pairs(self, text, only_present=False):
        pattern = r"([^:]+):\s*(.+)"
        pairs = re.findall(pattern, text)

        result = {}
        for key, value in pairs:
            key_clean = key.strip()
            value_clean = value.strip().lower()

            present_value = "–î–∞" if value_clean == "–¥–∞" else "–ù–µ"

            if only_present and present_value != "–î–∞":
                continue

            result[key_clean] = present_value

        return result


    def analyze_author_text(
    self,
    min_df=3,
    max_df=0.8904674508605334,
    max_features=4619,
    n_top_words=10,
    ngram_range=(1, 1),
    stop_words=None,
    skip_stopwords=True
):
       

        df = self.df.copy()
        df['song_text_processed'] = df['song_text'].str.lower().str.replace(r'[^\w\s]', '', regex=True)

        author_corpus = df.groupby("author")["song_text_processed"].apply(lambda x: " ".join(x)).reset_index()

        results = {'common_words': {}, 'expressive_words': {}}

        # Default stop words if not provided
        default_stop_words = [
            '—ú–µ', '–±–∏', '–∫–æ', '–≥–æ', '–∫–∞–∫–æ', '–≥–∏', '–º–∏', '—Ç–∏', '—Ç–µ', '–º—É', '—Å–∞–º–æ',
            '–∑–∞—à—Ç–æ', '—Ç–∞–∞', '—Ç–∏–µ', '–Ω√®', '–Ω–æ', '—Å√®', '—Å–æ', '–ø–æ', '–ª–∏', '–æ—ò', '–Ω–∏',
            '–Ω–∏—Ç—É', 'pinterest', '–¥–æ', '—Ç–∞–∞', '–Ω–∏–µ', '–≤–∏–µ', '—Ç–∏–µ', '—Å–∏','—Ç–æ','—Å–º–µ',
            '–±–∏–ª','—ò–∞—Å','–Ω–µ–∫–∞','–∫–æ–≥–∞','–∫–æ–ª–∫—É','—Ç–æ–∞','–¥–µ–∫–∞','–∏–ª–∏','–∑–∞—Ä','–∏–ª','–º–µ','—Å–æ',
            '–∫–æ—ò','–∫–æ–Ω','—Ç–∞','–æ–≤–∞–∞','–æ–≤–æ—ò','—Ç–æ—ò','–∫–∞—ò','—Å–µ','—Ç—É–∫—É','–Ω–∏–µ','–≤–∏–µ','—Ç–∏–µ','–Ω—ê'
        ]
        if stop_words is None:
            stop_words = default_stop_words

        for author in author_corpus['author']:
            texts = df[df['author'] == author]['song_text_processed']
            all_words = ' '.join(texts).split()

            # Remove author's own name
            author_names = author.lower().split()
            author_first_name = author_names[0] if len(author_names) > 0 else ''
            author_last_name = author_names[-1] if len(author_names) > 1 else ''

            if skip_stopwords:
                all_words = [word for word in all_words if word not in stop_words]

            all_words = [word for word in all_words if word not in [author_first_name, author_last_name]]

            word_counts = Counter(all_words)
            common_words = [(word, count) for word, count in word_counts.most_common(n_top_words)]
            results['common_words'][author] = common_words

        # TF-IDF part
        vectorizer = TfidfVectorizer(
            min_df=min_df,
            max_df=max_df,
            stop_words=stop_words if skip_stopwords else None,
            ngram_range=ngram_range,
            max_features=max_features
        )

        X = vectorizer.fit_transform(author_corpus["song_text_processed"])
        feature_names = vectorizer.get_feature_names_out()

        for idx, author in enumerate(author_corpus["author"]):
            author_names = author.lower().split()
            author_first_name = author_names[0] if len(author_names) > 0 else ''
            author_last_name = author_names[-1] if len(author_names) > 1 else ''

            tfidf_vector = X[idx].toarray()[0]
            top_indices = tfidf_vector.argsort()[-n_top_words * 2:][::-1]
            top_terms = [
                (feature_names[i], tfidf_vector[i])
                for i in top_indices
                if feature_names[i] not in [author_first_name, author_last_name]
            ]
            top_terms = top_terms[:n_top_words]
            results['expressive_words'][author] = top_terms

        print("\nMost Expressive Words per Author (TF-IDF Scores):")
        for author, words in results['expressive_words'].items():
            print(f"\n{author}:")
            for word, score in words:
                print(f"  {word}: {score:.3f}")

        return results
    def print_random_prompt(self):

        try:
            songs_to_apply = pd.read_csv('author_songs_to_create_only_with_styles.csv')

            random_row = songs_to_apply.sample(1).iloc[0]
            author = random_row['author']

            all_author_words = self.analyze_author_text()

            extracted_styles = self.extract_style_pairs(random_row['styles'], only_present=True)
            available_styles = list(extracted_styles.keys())

            if not available_styles:
                print(f"No styles found for author '{author}', skipping.")
                return

            
            # Create the final prompt
            prompt, styles_string = self.create_idf_styles_prompt(
                author=author,
                all_author_words=all_author_words,
                styles=available_styles
            )

            print("=== üé≠ Random Prompt Generated ===")
            print(f"Author: {author}")
            print("\n--- Prompt ---")
            print(prompt)
            print("-----------------------------")

            return prompt 

        except Exception as e:
            print(f"Error generating random prompt: {e}")
    def invoke_claude_model(self, prompt, system):
        response = self.client.converse(
            modelId="anthropic.claude-3-haiku-20240307-v1:0",
            messages=[
                {
                    "role": "user",
                    "content": [{"text": prompt}]
                }
            ],
            system=[{"text": system}],
            inferenceConfig={
                "maxTokens": 2000,
                "temperature": 1,
                "topP": 0.999
            }
        )
        return response
st = StyleTransferLocal(model="http://127.0.0.1:8080/v1/chat/completions")
total_start=time.time()
st.fill_csv_using__styles_idf(styles_from='all_styles_to_create.csv',model='claude',output_path='all_styles_idf_claude.csv')
print(f'Time in the end {time.time()-total_start} s')
#(1741+ 255 * 9)/60=67 –º–∏–Ω—É—Ç–∏  klod. 
#Best hyperparameters: {'max_features': 4619, 'n_layers': 1, 'neurons': 567, 'activation': 'tanh', 'dropout_rate': 0.3406819279083615, 'optimizer': 'rmsprop', 'lr': 0.0007878787378953067, 'l2_reg': 3.145848564707723e-05, 'n_epochs': 41, 'min_df': 3, 'max_df': 0.8904674508605334, 'ngram_range': '1-1'}
