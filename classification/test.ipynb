{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass FF_Classifier():\\n\\n    def __init__(self,split_ratio=0.7,random_seed=47,CSV_PATH=\"classification/kafe_kniga_songs.csv\"):\\n        self.rarandom_seed=random_seed=47\\n        np.random.seed(random_seed)\\n        random.seed(random_seed)\\n        #tf.random.set_seed(random_seed)\\n        self.database=pd.read_csv(CSV_PATH)\\n        print(self.database)\\n        self.database.drop()\\n\\n\\n\\ntest=FF_Classifier()'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\"\"\"\n",
    "class FF_Classifier():\n",
    "    \n",
    "    def __init__(self,split_ratio=0.7,random_seed=47,CSV_PATH=\"classification/kafe_kniga_songs.csv\"):\n",
    "        self.rarandom_seed=random_seed=47\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "        #tf.random.set_seed(random_seed)\n",
    "        self.database=pd.read_csv(CSV_PATH)\n",
    "        print(self.database)\n",
    "        self.database.drop()\n",
    "\n",
    "\n",
    "\n",
    "test=FF_Classifier()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH=\"song_kafe_kniga.csv\"\n",
    "database=pd.read_csv(CSV_PATH)\n",
    "random_seed=47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>context</th>\n",
       "      <th>song_title</th>\n",
       "      <th>song_text</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Петре М</td>\n",
       "      <td>Петок е прекрасен ден за читање поезија, па за...</td>\n",
       "      <td>Наопачно оро</td>\n",
       "      <td>Наопачно оро – Петре М. Андреевски\\n\\nКој игра...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>На 13 јуни 1943 година загинал Кочо Рацин. И п...</td>\n",
       "      <td>Балада за непознатиот</td>\n",
       "      <td>Балада за непознатиот – Кочо Рацин\\n\\nНатаму –...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Гане Тодоровски</td>\n",
       "      <td>На 22 мај 2010 година починал еден од најголем...</td>\n",
       "      <td>Молитва</td>\n",
       "      <td>Молитва – Гане Тодоровски\\n\\n(пред крајот на г...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Влада Урошевиќ</td>\n",
       "      <td>Денес на блогот читаме прекрасни македонски ст...</td>\n",
       "      <td>Слобода</td>\n",
       "      <td>Слобода – Влада Урошевиќ\\n\\nПтица со пет крила...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>Денес е 1 Мај, Меѓународен ден на трудот. Во т...</td>\n",
       "      <td>Копачите</td>\n",
       "      <td>Копачите – Кочо Рацин\\n\\nСе к’ти ноќта црна!\\n...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>236</td>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>Бели Мугри, Современа Македонска Поезија</td>\n",
       "      <td>На Струга дуќан да имам</td>\n",
       "      <td>\"3анаетот е златен... \"\\n\\n    Народна поговор...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>237</td>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>Бели Мугри, Современа Македонска Поезија</td>\n",
       "      <td>Проштавање</td>\n",
       "      <td>На печалбарите\\n\\n    Не ли ти кажав, не ли ти...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>238</td>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>Бели Мугри, Современа Македонска Поезија</td>\n",
       "      <td>Селска мака</td>\n",
       "      <td>Покрај ниви, покрај лаки\\n\\nпокрај снискине бр...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>239</td>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>Бели Мугри, Современа Македонска Поезија</td>\n",
       "      <td>Тутуноберачите</td>\n",
       "      <td>На кантар студен со туч го мерат\\n    а можат ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>235</td>\n",
       "      <td>Гане Тодоровски</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4ти МАЈ 1903</td>\n",
       "      <td>Така му било пишано: гробот да си го сони!\\n  ...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id           author                                            context  \\\n",
       "0      1          Петре М  Петок е прекрасен ден за читање поезија, па за...   \n",
       "1      2       Кочо Рацин  На 13 јуни 1943 година загинал Кочо Рацин. И п...   \n",
       "2      3  Гане Тодоровски  На 22 мај 2010 година починал еден од најголем...   \n",
       "3      4   Влада Урошевиќ  Денес на блогот читаме прекрасни македонски ст...   \n",
       "4      5       Кочо Рацин  Денес е 1 Мај, Меѓународен ден на трудот. Во т...   \n",
       "..   ...              ...                                                ...   \n",
       "233  236       Кочо Рацин           Бели Мугри, Современа Македонска Поезија   \n",
       "234  237       Кочо Рацин           Бели Мугри, Современа Македонска Поезија   \n",
       "235  238       Кочо Рацин           Бели Мугри, Современа Македонска Поезија   \n",
       "236  239       Кочо Рацин           Бели Мугри, Современа Македонска Поезија   \n",
       "237  235  Гане Тодоровски                                                NaN   \n",
       "\n",
       "                  song_title  \\\n",
       "0               Наопачно оро   \n",
       "1      Балада за непознатиот   \n",
       "2                    Молитва   \n",
       "3                    Слобода   \n",
       "4                   Копачите   \n",
       "..                       ...   \n",
       "233  На Струга дуќан да имам   \n",
       "234               Проштавање   \n",
       "235              Селска мака   \n",
       "236           Тутуноберачите   \n",
       "237             4ти МАЈ 1903   \n",
       "\n",
       "                                             song_text  author_id  \n",
       "0    Наопачно оро – Петре М. Андреевски\\n\\nКој игра...         40  \n",
       "1    Балада за непознатиот – Кочо Рацин\\n\\nНатаму –...         23  \n",
       "2    Молитва – Гане Тодоровски\\n\\n(пред крајот на г...         32  \n",
       "3    Слобода – Влада Урошевиќ\\n\\nПтица со пет крила...          4  \n",
       "4    Копачите – Кочо Рацин\\n\\nСе к’ти ноќта црна!\\n...         23  \n",
       "..                                                 ...        ...  \n",
       "233  \"3анаетот е златен... \"\\n\\n    Народна поговор...         23  \n",
       "234  На печалбарите\\n\\n    Не ли ти кажав, не ли ти...         23  \n",
       "235  Покрај ниви, покрај лаки\\n\\nпокрај снискине бр...         23  \n",
       "236  На кантар студен со туч го мерат\\n    а можат ...         23  \n",
       "237  Така му било пишано: гробот да си го сони!\\n  ...         32  \n",
       "\n",
       "[238 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "database=database.drop(columns='id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>context</th>\n",
       "      <th>song_title</th>\n",
       "      <th>song_text</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Петре М</td>\n",
       "      <td>Петок е прекрасен ден за читање поезија, па за...</td>\n",
       "      <td>Наопачно оро</td>\n",
       "      <td>Наопачно оро – Петре М. Андреевски\\n\\nКој игра...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>На 13 јуни 1943 година загинал Кочо Рацин. И п...</td>\n",
       "      <td>Балада за непознатиот</td>\n",
       "      <td>Балада за непознатиот – Кочо Рацин\\n\\nНатаму –...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Гане Тодоровски</td>\n",
       "      <td>На 22 мај 2010 година починал еден од најголем...</td>\n",
       "      <td>Молитва</td>\n",
       "      <td>Молитва – Гане Тодоровски\\n\\n(пред крајот на г...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Влада Урошевиќ</td>\n",
       "      <td>Денес на блогот читаме прекрасни македонски ст...</td>\n",
       "      <td>Слобода</td>\n",
       "      <td>Слобода – Влада Урошевиќ\\n\\nПтица со пет крила...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>Денес е 1 Мај, Меѓународен ден на трудот. Во т...</td>\n",
       "      <td>Копачите</td>\n",
       "      <td>Копачите – Кочо Рацин\\n\\nСе к’ти ноќта црна!\\n...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>Бели Мугри, Современа Македонска Поезија</td>\n",
       "      <td>На Струга дуќан да имам</td>\n",
       "      <td>\"3анаетот е златен... \"\\n\\n    Народна поговор...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>Бели Мугри, Современа Македонска Поезија</td>\n",
       "      <td>Проштавање</td>\n",
       "      <td>На печалбарите\\n\\n    Не ли ти кажав, не ли ти...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>Бели Мугри, Современа Македонска Поезија</td>\n",
       "      <td>Селска мака</td>\n",
       "      <td>Покрај ниви, покрај лаки\\n\\nпокрај снискине бр...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Кочо Рацин</td>\n",
       "      <td>Бели Мугри, Современа Македонска Поезија</td>\n",
       "      <td>Тутуноберачите</td>\n",
       "      <td>На кантар студен со туч го мерат\\n    а можат ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Гане Тодоровски</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4ти МАЈ 1903</td>\n",
       "      <td>Така му било пишано: гробот да си го сони!\\n  ...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                            context  \\\n",
       "0            Петре М  Петок е прекрасен ден за читање поезија, па за...   \n",
       "1         Кочо Рацин  На 13 јуни 1943 година загинал Кочо Рацин. И п...   \n",
       "2    Гане Тодоровски  На 22 мај 2010 година починал еден од најголем...   \n",
       "3     Влада Урошевиќ  Денес на блогот читаме прекрасни македонски ст...   \n",
       "4         Кочо Рацин  Денес е 1 Мај, Меѓународен ден на трудот. Во т...   \n",
       "..               ...                                                ...   \n",
       "233       Кочо Рацин           Бели Мугри, Современа Македонска Поезија   \n",
       "234       Кочо Рацин           Бели Мугри, Современа Македонска Поезија   \n",
       "235       Кочо Рацин           Бели Мугри, Современа Македонска Поезија   \n",
       "236       Кочо Рацин           Бели Мугри, Современа Македонска Поезија   \n",
       "237  Гане Тодоровски                                                NaN   \n",
       "\n",
       "                  song_title  \\\n",
       "0               Наопачно оро   \n",
       "1      Балада за непознатиот   \n",
       "2                    Молитва   \n",
       "3                    Слобода   \n",
       "4                   Копачите   \n",
       "..                       ...   \n",
       "233  На Струга дуќан да имам   \n",
       "234               Проштавање   \n",
       "235              Селска мака   \n",
       "236           Тутуноберачите   \n",
       "237             4ти МАЈ 1903   \n",
       "\n",
       "                                             song_text  author_id  \n",
       "0    Наопачно оро – Петре М. Андреевски\\n\\nКој игра...         40  \n",
       "1    Балада за непознатиот – Кочо Рацин\\n\\nНатаму –...         23  \n",
       "2    Молитва – Гане Тодоровски\\n\\n(пред крајот на г...         32  \n",
       "3    Слобода – Влада Урошевиќ\\n\\nПтица со пет крила...          4  \n",
       "4    Копачите – Кочо Рацин\\n\\nСе к’ти ноќта црна!\\n...         23  \n",
       "..                                                 ...        ...  \n",
       "233  \"3анаетот е златен... \"\\n\\n    Народна поговор...         23  \n",
       "234  На печалбарите\\n\\n    Не ли ти кажав, не ли ти...         23  \n",
       "235  Покрај ниви, покрај лаки\\n\\nпокрај снискине бр...         23  \n",
       "236  На кантар студен со туч го мерат\\n    а можат ...         23  \n",
       "237  Така му било пишано: гробот да си го сони!\\n  ...         32  \n",
       "\n",
       "[238 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(database['author'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "database=database.drop(columns='author_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw training without context using only words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in train_y: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26]\n",
      "Unique labels in test_y: [ 1  2  3  4  5  6  8  9 10 11 12 13 15 16 17 20 24 25 26]\n",
      "Number of classes: 27\n",
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1024 - loss: 3.2825 - val_accuracy: 0.0857 - val_loss: 3.2462\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1506 - loss: 3.1622 - val_accuracy: 0.0857 - val_loss: 3.0796\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1446 - loss: 2.8440 - val_accuracy: 0.0857 - val_loss: 3.0804\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1627 - loss: 2.6318 - val_accuracy: 0.1714 - val_loss: 2.8687\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2651 - loss: 2.4344 - val_accuracy: 0.2000 - val_loss: 2.8014\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3072 - loss: 2.1564 - val_accuracy: 0.1857 - val_loss: 2.7724\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4458 - loss: 1.8412 - val_accuracy: 0.3429 - val_loss: 2.6252\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6386 - loss: 1.4234 - val_accuracy: 0.3286 - val_loss: 2.6733\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7530 - loss: 1.0310 - val_accuracy: 0.4286 - val_loss: 2.6539\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7892 - loss: 0.7792 - val_accuracy: 0.4857 - val_loss: 2.5830\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8434 - loss: 0.6240 - val_accuracy: 0.4857 - val_loss: 2.5175\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8554 - loss: 0.5135 - val_accuracy: 0.5000 - val_loss: 2.4749\n",
      "Epoch 13/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8675 - loss: 0.4348 - val_accuracy: 0.4429 - val_loss: 2.6096\n",
      "Epoch 14/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9036 - loss: 0.3698 - val_accuracy: 0.4429 - val_loss: 2.4432\n",
      "Epoch 15/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9277 - loss: 0.2876 - val_accuracy: 0.4000 - val_loss: 2.4705\n",
      "Epoch 16/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9337 - loss: 0.2591 - val_accuracy: 0.4429 - val_loss: 2.5490\n",
      "Epoch 17/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9337 - loss: 0.2000 - val_accuracy: 0.4857 - val_loss: 2.4361\n",
      "Epoch 18/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9578 - loss: 0.1671 - val_accuracy: 0.5000 - val_loss: 2.2392\n",
      "Epoch 19/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9578 - loss: 0.1555 - val_accuracy: 0.5429 - val_loss: 2.3829\n",
      "Epoch 20/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9518 - loss: 0.1465 - val_accuracy: 0.5286 - val_loss: 2.0522\n",
      "Epoch 21/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9639 - loss: 0.1399 - val_accuracy: 0.4286 - val_loss: 2.3751\n",
      "Epoch 22/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9699 - loss: 0.1011 - val_accuracy: 0.3857 - val_loss: 3.6459\n",
      "Epoch 23/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9819 - loss: 0.0861 - val_accuracy: 0.3857 - val_loss: 3.8201\n",
      "Epoch 24/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0716 - val_accuracy: 0.4714 - val_loss: 3.1524\n",
      "Epoch 25/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9940 - loss: 0.0617 - val_accuracy: 0.4429 - val_loss: 2.9618\n",
      "Epoch 26/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.0497 - val_accuracy: 0.4143 - val_loss: 3.1858\n",
      "Epoch 27/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0348 - val_accuracy: 0.4571 - val_loss: 2.9503\n",
      "Epoch 28/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0284 - val_accuracy: 0.4714 - val_loss: 2.9258\n",
      "Epoch 29/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0322 - val_accuracy: 0.4714 - val_loss: 3.0015\n",
      "Epoch 30/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.4571 - val_loss: 3.3339\n",
      "Test Accuracy: 0.4571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Петре М\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "#only words\n",
    "\n",
    "only_song=['author','context']\n",
    "train,test=train_test_split(database,test_size=0.3,random_state=random_seed)\n",
    "train_x,train_y=train.drop(columns=only_song),train['author']\n",
    "test_x,test_y=test.drop(columns=only_song),test['author']\n",
    "\n",
    "train_texts = train_x[\"song_text\"].astype(str)\n",
    "test_texts = test_x[\"song_text\"].astype(str)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_texts).toarray()\n",
    "X_test = vectorizer.transform(test_texts).toarray()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_y_encoded = label_encoder.fit_transform(train_y)\n",
    "\n",
    "mask = test_y.isin(train_y)\n",
    "X_test = X_test[mask.values]\n",
    "test_y = test_y[mask]\n",
    "test_y_encoded = label_encoder.transform(test_y)\n",
    "\n",
    "print(\"Unique labels in train_y:\", np.unique(train_y_encoded))\n",
    "print(\"Unique labels in test_y:\", np.unique(test_y_encoded))\n",
    "print(\"Number of classes:\", len(label_encoder.classes_))\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(label_encoder.classes_)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "     layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(output_dim, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, train_y_encoded,\n",
    "    validation_data=(X_test, test_y_encoded),\n",
    "    epochs=30,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(X_test, test_y_encoded, verbose=0)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# ================================================\n",
    "# Prediction function (only text)\n",
    "# ================================================\n",
    "def predict_author(text):\n",
    "    new_vec = vectorizer.transform([text]).toarray()\n",
    "    pred = model.predict(new_vec)\n",
    "    return label_encoder.inverse_transform([pred.argmax()])[0]\n",
    "\n",
    "# Example usage\n",
    "print(predict_author(\"Сонцето изгрева на исток...\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "only_song = ['author', 'context']\n",
    "train, test = train_test_split(database, test_size=0.3, random_state=random_seed)\n",
    "train_x, train_y = train.drop(columns=only_song), train['author']\n",
    "test_x, test_y = test.drop(columns=only_song), test['author']\n",
    "\n",
    "train_texts = train_x[\"song_text\"].astype(str)\n",
    "test_texts = test_x[\"song_text\"].astype(str)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_texts).toarray()\n",
    "X_test = vectorizer.transform(test_texts).toarray()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_y_encoded = label_encoder.fit_transform(train_y)\n",
    "\n",
    "mask = test_y.isin(train_y)\n",
    "X_test = X_test[mask.values]\n",
    "test_y = test_y[mask]\n",
    "test_y_encoded = label_encoder.transform(test_y)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "    neurons = trial.suggest_categorical(\"neurons\", [64, 128, 256, 512])\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"elu\"])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    epochs = trial.suggest_int(\"epochs\", 5, 50) \n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "    for _ in range(n_layers):\n",
    "        model.add(layers.Dense(neurons, activation=activation))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "   \n",
    "    history = model.fit(\n",
    "        X_train, train_y_encoded,\n",
    "        validation_data=(X_test, test_y_encoded),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "    f1 = f1_score(test_y_encoded, y_pred, average=\"weighted\")\n",
    "    return f1\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best F1 Score:\", study.best_value)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 14:38:57,359] A new study created in memory with name: no-name-99dc9e28-b47d-49ec-ac9a-7d127c71daf9\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:39:09,367] Trial 0 finished with value: 0.12268099547511313 and parameters: {'embedding_dim': 128, 'n_layers': 2, 'neurons': 256, 'dropout_rate': 0.17452136399657947, 'optimizer': 'adam', 'lr': 0.0003323061477910434, 'epochs': 25}. Best is trial 0 with value: 0.12268099547511313.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:39:25,161] Trial 1 finished with value: 0.08984126984126983 and parameters: {'embedding_dim': 64, 'n_layers': 4, 'neurons': 64, 'dropout_rate': 0.42585298879530986, 'optimizer': 'adam', 'lr': 0.0005122513165008432, 'epochs': 41}. Best is trial 0 with value: 0.12268099547511313.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:40:14,872] Trial 2 finished with value: 0.08815295815295815 and parameters: {'embedding_dim': 256, 'n_layers': 10, 'neurons': 128, 'dropout_rate': 0.16910276672079888, 'optimizer': 'rmsprop', 'lr': 0.00033219014931832165, 'epochs': 46}. Best is trial 0 with value: 0.12268099547511313.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:40:22,877] Trial 3 finished with value: 0.03823326432022084 and parameters: {'embedding_dim': 64, 'n_layers': 2, 'neurons': 512, 'dropout_rate': 0.3468382663598002, 'optimizer': 'adam', 'lr': 0.00010879824517981457, 'epochs': 5}. Best is trial 0 with value: 0.12268099547511313.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:40:54,132] Trial 4 finished with value: 0.03961038961038961 and parameters: {'embedding_dim': 128, 'n_layers': 7, 'neurons': 64, 'dropout_rate': 0.27823164776937254, 'optimizer': 'sgd', 'lr': 0.000736789593515202, 'epochs': 47}. Best is trial 0 with value: 0.12268099547511313.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:41:00,803] Trial 5 finished with value: 0.08103174603174604 and parameters: {'embedding_dim': 128, 'n_layers': 2, 'neurons': 128, 'dropout_rate': 0.4787838280983622, 'optimizer': 'rmsprop', 'lr': 0.00012610138346532768, 'epochs': 21}. Best is trial 0 with value: 0.12268099547511313.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:41:46,624] Trial 6 finished with value: 0.009652509652509652 and parameters: {'embedding_dim': 256, 'n_layers': 9, 'neurons': 256, 'dropout_rate': 0.2572474716176507, 'optimizer': 'rmsprop', 'lr': 0.005515576712037304, 'epochs': 22}. Best is trial 0 with value: 0.12268099547511313.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:41:50,464] Trial 7 finished with value: 0.0138996138996139 and parameters: {'embedding_dim': 64, 'n_layers': 1, 'neurons': 256, 'dropout_rate': 0.49468778473420216, 'optimizer': 'sgd', 'lr': 0.008855876401926855, 'epochs': 13}. Best is trial 0 with value: 0.12268099547511313.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:42:30,325] Trial 8 finished with value: 0.01818181818181818 and parameters: {'embedding_dim': 64, 'n_layers': 8, 'neurons': 128, 'dropout_rate': 0.1059477741987665, 'optimizer': 'rmsprop', 'lr': 0.002639086623198383, 'epochs': 45}. Best is trial 0 with value: 0.12268099547511313.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:42:40,849] Trial 9 finished with value: 0.11353341336534613 and parameters: {'embedding_dim': 128, 'n_layers': 2, 'neurons': 64, 'dropout_rate': 0.36807502894419286, 'optimizer': 'adam', 'lr': 0.00017929472589288132, 'epochs': 41}. Best is trial 0 with value: 0.12268099547511313.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:43:15,597] Trial 10 finished with value: 0.013533834586466165 and parameters: {'embedding_dim': 128, 'n_layers': 5, 'neurons': 256, 'dropout_rate': 0.18720212920333135, 'optimizer': 'adam', 'lr': 0.0020314542689983542, 'epochs': 30}. Best is trial 0 with value: 0.12268099547511313.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:43:31,304] Trial 11 finished with value: 0.12426065162907268 and parameters: {'embedding_dim': 128, 'n_layers': 4, 'neurons': 64, 'dropout_rate': 0.3413449402176788, 'optimizer': 'adam', 'lr': 0.00025475679837408594, 'epochs': 35}. Best is trial 11 with value: 0.12426065162907268.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:45:01,724] Trial 12 finished with value: 0.013533834586466165 and parameters: {'embedding_dim': 128, 'n_layers': 4, 'neurons': 512, 'dropout_rate': 0.2072819744704762, 'optimizer': 'adam', 'lr': 0.000288046810559228, 'epochs': 32}. Best is trial 11 with value: 0.12426065162907268.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:45:34,535] Trial 13 finished with value: 0.013533834586466165 and parameters: {'embedding_dim': 128, 'n_layers': 4, 'neurons': 256, 'dropout_rate': 0.3336672686808558, 'optimizer': 'adam', 'lr': 0.0011606218342946012, 'epochs': 34}. Best is trial 11 with value: 0.12426065162907268.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:45:49,651] Trial 14 finished with value: 0.11121578995970859 and parameters: {'embedding_dim': 128, 'n_layers': 6, 'neurons': 64, 'dropout_rate': 0.10106620679447131, 'optimizer': 'adam', 'lr': 0.0002665493144690823, 'epochs': 21}. Best is trial 11 with value: 0.12426065162907268.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:46:16,046] Trial 15 finished with value: 0.08745341614906832 and parameters: {'embedding_dim': 128, 'n_layers': 3, 'neurons': 256, 'dropout_rate': 0.404951434824953, 'optimizer': 'adam', 'lr': 0.0004974353293554545, 'epochs': 36}. Best is trial 11 with value: 0.12426065162907268.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:46:32,313] Trial 16 finished with value: 0.03964394268345636 and parameters: {'embedding_dim': 256, 'n_layers': 6, 'neurons': 64, 'dropout_rate': 0.22441934579198133, 'optimizer': 'sgd', 'lr': 0.00020701203669077646, 'epochs': 25}. Best is trial 11 with value: 0.12426065162907268.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:46:43,593] Trial 17 finished with value: 0.004696673189823875 and parameters: {'embedding_dim': 128, 'n_layers': 1, 'neurons': 512, 'dropout_rate': 0.31900270506631656, 'optimizer': 'adam', 'lr': 0.001403465705898965, 'epochs': 15}. Best is trial 11 with value: 0.12426065162907268.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:47:04,525] Trial 18 finished with value: 0.08028784163237945 and parameters: {'embedding_dim': 128, 'n_layers': 3, 'neurons': 256, 'dropout_rate': 0.2491917449193026, 'optimizer': 'adam', 'lr': 0.0004966167322042887, 'epochs': 27}. Best is trial 11 with value: 0.12426065162907268.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:47:25,321] Trial 19 finished with value: 0.07315523556902867 and parameters: {'embedding_dim': 256, 'n_layers': 5, 'neurons': 64, 'dropout_rate': 0.1600689986579968, 'optimizer': 'sgd', 'lr': 0.0007292128539825863, 'epochs': 38}. Best is trial 11 with value: 0.12426065162907268.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:47:32,735] Trial 20 finished with value: 0.09925685425685425 and parameters: {'embedding_dim': 128, 'n_layers': 3, 'neurons': 64, 'dropout_rate': 0.38758454022178834, 'optimizer': 'adam', 'lr': 0.00018068676066561955, 'epochs': 17}. Best is trial 11 with value: 0.12426065162907268.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:47:45,793] Trial 21 finished with value: 0.12505602240896357 and parameters: {'embedding_dim': 128, 'n_layers': 2, 'neurons': 64, 'dropout_rate': 0.3652742158997401, 'optimizer': 'adam', 'lr': 0.00016854258900292978, 'epochs': 40}. Best is trial 21 with value: 0.12505602240896357.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:47:54,457] Trial 22 finished with value: 0.08224315367172512 and parameters: {'embedding_dim': 128, 'n_layers': 1, 'neurons': 64, 'dropout_rate': 0.29631487710410764, 'optimizer': 'adam', 'lr': 0.00010399338848197317, 'epochs': 50}. Best is trial 21 with value: 0.12505602240896357.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:48:08,687] Trial 23 finished with value: 0.05807081807081808 and parameters: {'embedding_dim': 128, 'n_layers': 3, 'neurons': 64, 'dropout_rate': 0.4447862526001382, 'optimizer': 'adam', 'lr': 0.0003598542110873167, 'epochs': 39}. Best is trial 21 with value: 0.12505602240896357.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:48:17,051] Trial 24 finished with value: 0.0748955722639933 and parameters: {'embedding_dim': 128, 'n_layers': 2, 'neurons': 64, 'dropout_rate': 0.360014502972062, 'optimizer': 'adam', 'lr': 0.0001585453063319925, 'epochs': 29}. Best is trial 21 with value: 0.12505602240896357.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:48:49,290] Trial 25 finished with value: 0.06282372598162071 and parameters: {'embedding_dim': 128, 'n_layers': 4, 'neurons': 256, 'dropout_rate': 0.14352047181044175, 'optimizer': 'adam', 'lr': 0.00022297571940613933, 'epochs': 34}. Best is trial 21 with value: 0.12505602240896357.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:49:46,497] Trial 26 finished with value: 0.013533834586466165 and parameters: {'embedding_dim': 128, 'n_layers': 2, 'neurons': 512, 'dropout_rate': 0.31028031640333675, 'optimizer': 'adam', 'lr': 0.0003944518022474135, 'epochs': 41}. Best is trial 21 with value: 0.12505602240896357.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:50:02,980] Trial 27 finished with value: 0.0426890756302521 and parameters: {'embedding_dim': 128, 'n_layers': 5, 'neurons': 128, 'dropout_rate': 0.2804299900570142, 'optimizer': 'adam', 'lr': 0.000742034892849522, 'epochs': 24}. Best is trial 21 with value: 0.12505602240896357.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:50:08,823] Trial 28 finished with value: 0.0 and parameters: {'embedding_dim': 256, 'n_layers': 1, 'neurons': 64, 'dropout_rate': 0.3968793268407451, 'optimizer': 'sgd', 'lr': 0.00014296223497736854, 'epochs': 31}. Best is trial 21 with value: 0.12505602240896357.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:50:14,995] Trial 29 finished with value: 0.0463851937536148 and parameters: {'embedding_dim': 64, 'n_layers': 4, 'neurons': 64, 'dropout_rate': 0.41703716669897006, 'optimizer': 'rmsprop', 'lr': 0.00025676592121410305, 'epochs': 10}. Best is trial 21 with value: 0.12505602240896357.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:50:44,344] Trial 30 finished with value: 0.013533834586466165 and parameters: {'embedding_dim': 64, 'n_layers': 3, 'neurons': 256, 'dropout_rate': 0.4461440169268376, 'optimizer': 'adam', 'lr': 0.0005323926202568649, 'epochs': 42}. Best is trial 21 with value: 0.12505602240896357.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:50:55,570] Trial 31 finished with value: 0.14970049558284854 and parameters: {'embedding_dim': 128, 'n_layers': 2, 'neurons': 64, 'dropout_rate': 0.37253909734847196, 'optimizer': 'adam', 'lr': 0.00017567222400941197, 'epochs': 42}. Best is trial 31 with value: 0.14970049558284854.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:51:07,052] Trial 32 finished with value: 0.10341372912801483 and parameters: {'embedding_dim': 128, 'n_layers': 2, 'neurons': 64, 'dropout_rate': 0.3730621931866403, 'optimizer': 'adam', 'lr': 0.00014670415765320182, 'epochs': 44}. Best is trial 31 with value: 0.14970049558284854.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:51:15,687] Trial 33 finished with value: 0.19741342690922523 and parameters: {'embedding_dim': 128, 'n_layers': 1, 'neurons': 64, 'dropout_rate': 0.33444132788906505, 'optimizer': 'adam', 'lr': 0.0003695890200258645, 'epochs': 37}. Best is trial 33 with value: 0.19741342690922523.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:51:22,609] Trial 34 finished with value: 0.24921186656480776 and parameters: {'embedding_dim': 128, 'n_layers': 1, 'neurons': 64, 'dropout_rate': 0.337268541525661, 'optimizer': 'adam', 'lr': 0.0003787303253136525, 'epochs': 37}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:51:31,069] Trial 35 finished with value: 0.12430426716141 and parameters: {'embedding_dim': 128, 'n_layers': 1, 'neurons': 64, 'dropout_rate': 0.32562943724618526, 'optimizer': 'adam', 'lr': 0.0003734883979604811, 'epochs': 49}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:51:37,718] Trial 36 finished with value: 0.10456282513005202 and parameters: {'embedding_dim': 128, 'n_layers': 1, 'neurons': 64, 'dropout_rate': 0.3804147663991775, 'optimizer': 'adam', 'lr': 0.00010085701467845725, 'epochs': 37}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:51:50,467] Trial 37 finished with value: 0.14581453634085215 and parameters: {'embedding_dim': 256, 'n_layers': 2, 'neurons': 64, 'dropout_rate': 0.43519774823385726, 'optimizer': 'rmsprop', 'lr': 0.000611606542978865, 'epochs': 43}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:52:36,662] Trial 38 finished with value: 0.08105019305019306 and parameters: {'embedding_dim': 256, 'n_layers': 10, 'neurons': 64, 'dropout_rate': 0.43997838054348987, 'optimizer': 'rmsprop', 'lr': 0.000920378633603943, 'epochs': 47}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:52:46,207] Trial 39 finished with value: 0.042084033613445385 and parameters: {'embedding_dim': 256, 'n_layers': 1, 'neurons': 128, 'dropout_rate': 0.42443751500989735, 'optimizer': 'rmsprop', 'lr': 0.0005959786910465987, 'epochs': 43}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:52:59,703] Trial 40 finished with value: 0.09535223230875405 and parameters: {'embedding_dim': 256, 'n_layers': 2, 'neurons': 64, 'dropout_rate': 0.4747411245822512, 'optimizer': 'rmsprop', 'lr': 0.0004272683508029392, 'epochs': 46}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:53:08,003] Trial 41 finished with value: 0.20350086421514996 and parameters: {'embedding_dim': 256, 'n_layers': 1, 'neurons': 64, 'dropout_rate': 0.35012372264320996, 'optimizer': 'rmsprop', 'lr': 0.00031263605635205126, 'epochs': 39}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:53:16,227] Trial 42 finished with value: 0.1304230410112763 and parameters: {'embedding_dim': 256, 'n_layers': 1, 'neurons': 64, 'dropout_rate': 0.35090619041080523, 'optimizer': 'rmsprop', 'lr': 0.0003179067812157458, 'epochs': 39}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:53:28,982] Trial 43 finished with value: 0.09553090801538007 and parameters: {'embedding_dim': 256, 'n_layers': 2, 'neurons': 64, 'dropout_rate': 0.30421215749371056, 'optimizer': 'rmsprop', 'lr': 0.0006290107643657623, 'epochs': 43}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:53:36,064] Trial 44 finished with value: 0.14142279942279942 and parameters: {'embedding_dim': 256, 'n_layers': 1, 'neurons': 64, 'dropout_rate': 0.28781282065777836, 'optimizer': 'rmsprop', 'lr': 0.0009531662165230939, 'epochs': 33}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:54:44,262] Trial 45 finished with value: 0.08318216175359032 and parameters: {'embedding_dim': 256, 'n_layers': 2, 'neurons': 512, 'dropout_rate': 0.261242363954265, 'optimizer': 'rmsprop', 'lr': 0.00021824106009110994, 'epochs': 47}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:55:21,537] Trial 46 finished with value: 0.057783393077510715 and parameters: {'embedding_dim': 64, 'n_layers': 8, 'neurons': 128, 'dropout_rate': 0.34709539692543273, 'optimizer': 'rmsprop', 'lr': 0.00031165879703439224, 'epochs': 37}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:55:39,012] Trial 47 finished with value: 0.07322950232724668 and parameters: {'embedding_dim': 256, 'n_layers': 3, 'neurons': 64, 'dropout_rate': 0.47024905774897924, 'optimizer': 'rmsprop', 'lr': 0.00043271258181051044, 'epochs': 45}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:55:45,715] Trial 48 finished with value: 0.0336734693877551 and parameters: {'embedding_dim': 256, 'n_layers': 1, 'neurons': 64, 'dropout_rate': 0.40747510854341595, 'optimizer': 'sgd', 'lr': 0.003127557644461983, 'epochs': 36}. Best is trial 34 with value: 0.24921186656480776.\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "[I 2025-09-07 14:55:56,228] Trial 49 finished with value: 0.1489933625271971 and parameters: {'embedding_dim': 64, 'n_layers': 2, 'neurons': 64, 'dropout_rate': 0.3265082486445502, 'optimizer': 'rmsprop', 'lr': 0.0001244294377122405, 'epochs': 41}. Best is trial 34 with value: 0.24921186656480776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 Score: 0.24921186656480776\n",
      "Best hyperparameters: {'embedding_dim': 128, 'n_layers': 1, 'neurons': 64, 'dropout_rate': 0.337268541525661, 'optimizer': 'adam', 'lr': 0.0003787303253136525, 'epochs': 37}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# ================================================\n",
    "# Prepare dataset\n",
    "# ================================================\n",
    "only_song = ['author', 'context']\n",
    "train, test = train_test_split(database, test_size=0.3, random_state=random_seed)\n",
    "train_x, train_y = train.drop(columns=only_song), train['author']\n",
    "test_x, test_y = test.drop(columns=only_song), test['author']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_y_encoded = label_encoder.fit_transform(train_y)\n",
    "mask = test_y.isin(train_y)\n",
    "test_y = test_y[mask]\n",
    "X_test_raw = test_x[mask]['song_text'].astype(str)\n",
    "test_y_encoded = label_encoder.transform(test_y)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Tokenize text for RNN\n",
    "max_words = 10000  # vocabulary size\n",
    "max_len = 200      # maximum sequence length\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_x[\"song_text\"].astype(str))\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_x[\"song_text\"].astype(str))\n",
    "X_train_seq = keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_raw)\n",
    "X_test_seq = keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "# ================================================\n",
    "# Define Optuna objective for RNN\n",
    "# ================================================\n",
    "def objective(trial):\n",
    "\n",
    "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256])    \n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "    units = trial.suggest_categorical(\"neurons\", [64, 128, 256, 512])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    epochs = trial.suggest_int(\"epochs\", 5, 50) \n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
    "    \n",
    "    # Add stacked RNN layers if n_layers > 1\n",
    "    for i in range(n_layers):\n",
    "        return_sequences = i < n_layers - 1  # all but last return sequences\n",
    "        model.add(layers.SimpleRNN(units, return_sequences=return_sequences))\n",
    "    \n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    # Optimizer selection\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "   \n",
    "    history = model.fit(\n",
    "        X_train_seq, train_y_encoded,\n",
    "        validation_data=(X_test_seq, test_y_encoded),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_test_seq, verbose=0), axis=1)\n",
    "    f1 = f1_score(test_y_encoded, y_pred, average=\"weighted\")\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)  \n",
    "\n",
    "print(\"Best F1 Score:\", study.best_value)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 17:46:28,497] A new study created in memory with name: no-name-aa4892bd-fee8-4e09-9b8f-2f6391ca9d66\n",
      "/home/ivan/Desktop/Diplomska/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "only_song = ['author', 'context']\n",
    "train, test = train_test_split(database, test_size=0.3, random_state=random_seed)\n",
    "train_x, train_y = train.drop(columns=only_song), train['author']\n",
    "test_x, test_y = test.drop(columns=only_song), test['author']\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_y_encoded = label_encoder.fit_transform(train_y)\n",
    "mask = test_y.isin(train_y)\n",
    "test_y = test_y[mask]\n",
    "X_test_raw = test_x[mask]['song_text'].astype(str)\n",
    "test_y_encoded = label_encoder.transform(test_y)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "max_words = 10000  \n",
    "max_len = 200      \n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_x[\"song_text\"].astype(str))\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_x[\"song_text\"].astype(str))\n",
    "X_train_seq = keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_raw)\n",
    "X_test_seq = keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256,512])    \n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "    units = trial.suggest_categorical(\"neurons\", [64, 128, 256,512])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    epochs = trial.suggest_int(\"epochs\", 5, 50) \n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
    "\n",
    " \n",
    "    for i in range(n_layers):\n",
    "        return_sequences = i < n_layers - 1  \n",
    "        model.add(layers.LSTM(units, activation=\"tanh\", return_sequences=return_sequences))\n",
    "\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_seq, train_y_encoded,\n",
    "        validation_data=(X_test_seq, test_y_encoded),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_test_seq, verbose=0), axis=1)\n",
    "    f1 = f1_score(test_y_encoded, y_pred, average=\"weighted\")\n",
    "    return f1\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)  \n",
    "\n",
    "print(\"Best F1 Score:\", study.best_value)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
